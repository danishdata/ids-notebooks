{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dummy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "file_path = '%s/../Data_EDA.csv'%BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, encoding=\"latin-1\")\n",
    "\n",
    "X_cols = [col_name for col_name in df.columns if (df[col_name].dtype == 'int64' and col_name != 'ORDER_STATUS')]\n",
    "X = df[X_cols].values\n",
    "y = df.ORDER_STATUS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- APPLYING BASIC DATA MODELING --------------------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tLinear SVC                0.483167912533\n",
      "\tK Nearest Neighbours      0.610999858848\n",
      "\tDecision Trees            0.58909572917\n",
      "\tGradient Boosting         0.621142106861\n",
      "\tMLP Classifier            0.541519228836\n",
      "\tRandom Forest             0.611259384476\n",
      "\tBernoulliNB               0.576036278097\n",
      "\tNaive Bayes               0.575236926853\n",
      "\tLogistic Regression       0.580043372729\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.621060\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 3393  7082]\n",
      " [ 2044 11564]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- APPLYING DATA MODELING WITH GRID SEARCH CV FOR PARAMETER SELECTION -------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models having random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n"
     ]
    }
   ],
   "source": [
    "print('------- APPLYING DATA MODELING WITH GRID SEARCH CV FOR PARAMETER SELECTION -------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'K Nearest Neighbours'   : KNeighborsClassifier(),\n",
    "            'SVC'                    : SVC(random_state = random_no),\n",
    "            'MLP Classifier'         : MLPClassifier(random_state = random_no),\n",
    "            'Logistic Regression'    : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'         : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'          : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'      : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "params_obj = {\n",
    "            'K Nearest Neighbours'   : {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance']},\n",
    "            'SVC'                    : {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                                        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                                        'kernel': ['linear', 'rbf']},\n",
    "            'MLP Classifier'         : {'activation' : ['logistic', 'tanh', 'relu'],\n",
    "                                        'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "                                        'hidden_layer_sizes' : [[10], [100], [10, 100]],\n",
    "                                        'alpha' : [0.0001, 0.001, 0.01, 0.1, 1]},\n",
    "            'Logistic Regression'    : {'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "            'Decision Trees'         : {'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', None]},\n",
    "            'Random Forest'          : {'criterion': ['gini', 'entropy'], 'n_estimators': [10, 100, 1000]},\n",
    "            'Gradient Boosting'      : {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 1000]}\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models having random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(list)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    grid = GridSearchCV(clf, param_grid = params_obj[model_name], cv = splits, n_jobs = 3, pre_dispatch = '2*n_jobs')\n",
    "    grid.fit(train_X, train_y)\n",
    "    model_cs[model_name] = [grid.best_score_, grid.best_params_]\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, insight in model_cs.items():\n",
    "    print(\"\\t{0:25} {1:20} {2}\".format(model_name, str(insight[0]), str(insight[1])))\n",
    "    \n",
    "best_model = [model_name for model_name, insight in model_cs.items() if insight[0] == max([x[0] for x in model_cs.values()])][0]\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = models[best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit(train_X, train_y)\n",
    "# pred_y = model.predict(test_X)\n",
    "\n",
    "# print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "# print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "# print('7. Populating the confusion matrix')\n",
    "# print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 0.65346604]\n",
      "2 [ 0.65346604  0.28585104]\n",
      "3 [ 0.65346604  0.28585104  0.041134  ]\n",
      "4 [ 0.65346604  0.28585104  0.041134    0.01890879]\n"
     ]
    }
   ],
   "source": [
    "for component in range(1,5):\n",
    "    pca = PCA(n_components=component)\n",
    "    pca.fit(X)\n",
    "    print(component, pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- APPLYING BASIC DATA MODELING ON PCA APPLIED DATA ----------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tLinear SVC                0.513977989893\n",
      "\tK Nearest Neighbours      0.607906243755\n",
      "\tDecision Trees            0.583801358279\n",
      "\tGradient Boosting         0.608093110592\n",
      "\tMLP Classifier            0.534097016353\n",
      "\tRandom Forest             0.591742906533\n",
      "\tBernoulliNB               0.57572484648\n",
      "\tNaive Bayes               0.57605705461\n",
      "\tLogistic Regression       0.57482167895\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.610721\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 2809  7666]\n",
      " [ 1709 11899]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('---------------- APPLYING BASIC DATA MODELING ON PCA APPLIED DATA ----------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "pca = PCA(n_components = 2, random_state=random_no)\n",
    "X_p = pca.fit(X).transform(X)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_p, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- APPLYING BASIC DATA MODELING ON MIN-MAX SCALED DATA --------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0"
     ]
    }
   ],
   "source": [
    "print('--------------- APPLYING BASIC DATA MODELING ON MIN-MAX SCALED DATA --------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "X_scaled = MinMaxScaler().fit(X).transform(X)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_scaled, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-541387212ac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "for component in range(1,5):\n",
    "    pca = PCA(n_components=component)\n",
    "    pca.fit(X_scaled)\n",
    "    print(component, pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21370274  0.19434621  0.10001686  0.0922707   0.06556503  0.05720512\n",
      "  0.05282751  0.04830007  0.04729018  0.03825636  0.03633813  0.01770744]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95, random_state=random_no)\n",
    "pca.fit(X_scaled)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ APPLYING BASIC DATA MODELING ON MIN-MAX SCALED AND PCA APPLIED DATA ------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tLinear SVC                0.497265286144\n",
      "\tNaive Bayes               0.575226555032\n",
      "\tGradient Boosting         0.615401382301\n",
      "\tDecision Trees            0.591825973788\n",
      "\tLogistic Regression       0.579129825294\n",
      "\tRandom Forest             0.613937659522\n",
      "\tK Nearest Neighbours      0.611165914147\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.613254\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 3152  7323]\n",
      " [ 1991 11617]]\n"
     ]
    }
   ],
   "source": [
    "print('------ APPLYING BASIC DATA MODELING ON MIN-MAX SCALED AND PCA APPLIED DATA ------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "X_scaled = MinMaxScaler().fit(X).transform(X)\n",
    "pca = PCA(n_components = 0.95, random_state=random_no)\n",
    "X_p = pca.fit(X_scaled).transform(X)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_p, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
