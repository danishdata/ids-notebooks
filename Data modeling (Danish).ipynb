{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dummy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "file_path = '%s/../Data_EDA.csv'%BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, encoding=\"latin-1\")\n",
    "\n",
    "X_cols = [col_name for col_name in df.columns if (df[col_name].dtype == 'int64' and col_name != 'ORDER_STATUS')]\n",
    "X = df[X_cols].values\n",
    "y = df.ORDER_STATUS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- APPLYING BASIC DATA MODELING --------------------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tLinear SVC                0.483167912533\n",
      "\tK Nearest Neighbours      0.610999858848\n",
      "\tDecision Trees            0.58909572917\n",
      "\tGradient Boosting         0.621142106861\n",
      "\tMLP Classifier            0.541519228836\n",
      "\tRandom Forest             0.611259384476\n",
      "\tBernoulliNB               0.576036278097\n",
      "\tNaive Bayes               0.575236926853\n",
      "\tLogistic Regression       0.580043372729\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.621060\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 3393  7082]\n",
      " [ 2044 11564]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- APPLYING DATA MODELING WITH GRID SEARCH CV FOR PARAMETER SELECTION -------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models having random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n"
     ]
    }
   ],
   "source": [
    "print('------- APPLYING DATA MODELING WITH GRID SEARCH CV FOR PARAMETER SELECTION -------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'K Nearest Neighbours'   : KNeighborsClassifier(),\n",
    "            'SVC'                    : SVC(random_state = random_no),\n",
    "            'MLP Classifier'         : MLPClassifier(random_state = random_no),\n",
    "            'Logistic Regression'    : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'         : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'          : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'      : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "params_obj = {\n",
    "            'K Nearest Neighbours'   : {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance']},\n",
    "            'SVC'                    : {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                                        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                                        'kernel': ['linear', 'rbf']},\n",
    "            'MLP Classifier'         : {'activation' : ['logistic', 'tanh', 'relu'],\n",
    "                                        'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "                                        'hidden_layer_sizes' : [[10], [100], [10, 100]],\n",
    "                                        'alpha' : [0.0001, 0.001, 0.01, 0.1, 1]},\n",
    "            'Logistic Regression'    : {'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "            'Decision Trees'         : {'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', None]},\n",
    "            'Random Forest'          : {'criterion': ['gini', 'entropy'], 'n_estimators': [10, 100, 1000]},\n",
    "            'Gradient Boosting'      : {'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [100, 1000]}\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models having random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(list)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    grid = GridSearchCV(clf, param_grid = params_obj[model_name], cv = splits, n_jobs = 3, pre_dispatch = '2*n_jobs')\n",
    "    grid.fit(train_X, train_y)\n",
    "    model_cs[model_name] = [grid.best_score_, grid.best_params_]\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, insight in model_cs.items():\n",
    "    print(\"\\t{0:25} {1:20} {2}\".format(model_name, str(insight[0]), str(insight[1])))\n",
    "    \n",
    "best_model = [model_name for model_name, insight in model_cs.items() if insight[0] == max([x[0] for x in model_cs.values()])][0]\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = models[best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit(train_X, train_y)\n",
    "# pred_y = model.predict(test_X)\n",
    "\n",
    "# print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "# print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "# print('7. Populating the confusion matrix')\n",
    "# print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- APPLYING DATA MODELING WITH GRID SEARCH CV FOR PARAMETER SELECTION -------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models having random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Finding mean cross validation score for each model\n",
      "\tDecision Trees            0.591524878282       {'class_weight': 'balanced', 'criterion': 'entropy'}\n",
      "\tK Nearest Neighbours      0.626104288428       {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "\tLogistic Regression       0.580780450332       {'C': 0.01}\n",
      "\n",
      "5. Applying best model i.e. K Nearest Neighbours on the test dataset\n"
     ]
    }
   ],
   "source": [
    "print('------- APPLYING DATA MODELING WITH GRID SEARCH CV FOR PARAMETER SELECTION -------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'K Nearest Neighbours'   : KNeighborsClassifier(),\n",
    "            'Logistic Regression'    : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'         : DecisionTreeClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "params_obj = {\n",
    "            'K Nearest Neighbours'   : {'n_neighbors': [3, 5, 7, 9, 11], 'weights': ['uniform', 'distance']},\n",
    "            'Logistic Regression'    : {'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "            'Decision Trees'         : {'criterion': ['gini', 'entropy'], 'class_weight': ['balanced', None]}\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models having random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(list)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    grid = GridSearchCV(clf, param_grid = params_obj[model_name], cv = splits, n_jobs = 3, pre_dispatch = '2*n_jobs')\n",
    "    grid.fit(train_X, train_y)\n",
    "    model_cs[model_name] = [grid.best_score_, grid.best_params_]\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, insight in model_cs.items():\n",
    "    print(\"\\t{0:25} {1:20} {2}\".format(model_name, str(insight[0]), str(insight[1])))\n",
    "    \n",
    "best_model = [model_name for model_name, insight in model_cs.items() if insight[0] == max([x[0] for x in model_cs.values()])][0]\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [ 0.65346604]\n",
      "2 [ 0.65346604  0.28585104]\n",
      "3 [ 0.65346604  0.28585104  0.041134  ]\n",
      "4 [ 0.65346604  0.28585104  0.041134    0.01890879]\n"
     ]
    }
   ],
   "source": [
    "for component in range(1,5):\n",
    "    pca = PCA(n_components=component)\n",
    "    pca.fit(X)\n",
    "    print(component, pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- APPLYING BASIC DATA MODELING ON PCA APPLIED DATA ----------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tLinear SVC                0.513977989893\n",
      "\tK Nearest Neighbours      0.607906243755\n",
      "\tDecision Trees            0.583801358279\n",
      "\tGradient Boosting         0.608093110592\n",
      "\tMLP Classifier            0.534097016353\n",
      "\tRandom Forest             0.591742906533\n",
      "\tBernoulliNB               0.57572484648\n",
      "\tNaive Bayes               0.57605705461\n",
      "\tLogistic Regression       0.57482167895\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.610721\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 2809  7666]\n",
      " [ 1709 11899]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('---------------- APPLYING BASIC DATA MODELING ON PCA APPLIED DATA ----------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "pca = PCA(n_components = 2, random_state=random_no)\n",
    "X_p = pca.fit(X).transform(X)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_p, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- APPLYING BASIC DATA MODELING ON MIN-MAX SCALED DATA --------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0"
     ]
    }
   ],
   "source": [
    "print('--------------- APPLYING BASIC DATA MODELING ON MIN-MAX SCALED DATA --------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "X_scaled = MinMaxScaler().fit(X).transform(X)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_scaled, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-541387212ac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "for component in range(1,5):\n",
    "    pca = PCA(n_components=component)\n",
    "    pca.fit(X_scaled)\n",
    "    print(component, pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21370274  0.19434621  0.10001686  0.0922707   0.06556503  0.05720512\n",
      "  0.05282751  0.04830007  0.04729018  0.03825636  0.03633813  0.01770744]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95, random_state=random_no)\n",
    "pca.fit(X_scaled)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ APPLYING BASIC DATA MODELING ON MIN-MAX SCALED AND PCA APPLIED DATA ------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tLinear SVC                0.497265286144\n",
      "\tNaive Bayes               0.575226555032\n",
      "\tGradient Boosting         0.615401382301\n",
      "\tDecision Trees            0.591825973788\n",
      "\tLogistic Regression       0.579129825294\n",
      "\tRandom Forest             0.613937659522\n",
      "\tK Nearest Neighbours      0.611165914147\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.613254\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 3152  7323]\n",
      " [ 1991 11617]]\n"
     ]
    }
   ],
   "source": [
    "print('------ APPLYING BASIC DATA MODELING ON MIN-MAX SCALED AND PCA APPLIED DATA ------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "X_scaled = MinMaxScaler().fit(X).transform(X)\n",
    "pca = PCA(n_components = 0.95, random_state=random_no)\n",
    "X_p = pca.fit(X_scaled).transform(X)\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_p, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Naive Bayes'          : GaussianNB(),\n",
    "            'BernoulliNB'          : BernoulliNB(),\n",
    "            'K Nearest Neighbours' : KNeighborsClassifier(),\n",
    "            'MLP Classifier'       : MLPClassifier(random_state = random_no),\n",
    "            'Linear SVC'           : LinearSVC(random_state = random_no),\n",
    "            'Logistic Regression'  : LogisticRegression(random_state = random_no),\n",
    "            'Decision Trees'       : DecisionTreeClassifier(random_state = random_no),\n",
    "            'Random Forest'        : RandomForestClassifier(random_state = random_no),\n",
    "            'Gradient Boosting'    : GradientBoostingClassifier(random_state = random_no)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be done by Affan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Random_Forest_gini_100'    : RandomForestClassifier(random_state = random_no, criterion = 'gini', n_estimators = 100)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Random_Forest_entropy_10'    : RandomForestClassifier(random_state = random_no, criterion = 'entropy', n_estimators = 10)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- APPLYING BASIC DATA MODELING --------------------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-88b6c470ca70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mmodel_cs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Gradient Boosting_0.1_100'    : GradientBoostingClassifier(\n",
    "                                        random_state = random_no, learning_rate = 0.1, n_estimators = 100)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- APPLYING BASIC DATA MODELING --------------------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n",
      "4. Finding mean cross validation score for each model\n",
      "\tGradient Boosting_0.1_100 0.587766923594\n",
      "\n",
      "5. Applying best model i.e. Gradient Boosting_0.1_100 on the test dataset\n",
      "6. Finding accuracy using accuracy_score/clf.score\n",
      "\tTest accuracy score: 0.589918\n",
      "\n",
      "7. Populating the confusion matrix\n",
      "[[ 1568  8907]\n",
      " [  969 12639]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Gradient Boosting_0.01_100'    : GradientBoostingClassifier(\n",
    "                                        random_state = random_no, learning_rate = 0.01, n_estimators = 100)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be done by Haris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Random_Forest_gini_1000'    : RandomForestClassifier(random_state = random_no, criterion = 'gini', n_estimators = 1000)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Random_Forest_entropy_1000'    : RandomForestClassifier(random_state = random_no, criterion = 'entropy', n_estimators = 1000)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- APPLYING BASIC DATA MODELING --------------------------\n",
      "\n",
      "1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2\n",
      "2. Iterating through multiple classification models with random_state = 0\n",
      "3. Applying cross validation with number of splits = 5 on train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cb2a28b986fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mmodel_cs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thinkpad-marketiq/anaconda2/envs/_ids/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Gradient Boosting_0.001_100'    : GradientBoostingClassifier(\n",
    "                                        random_state = random_no, learning_rate = 0.001, n_estimators = 100)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Gradient Boosting_0.1_1000'    : GradientBoostingClassifier(\n",
    "                                        random_state = random_no, learning_rate = 0.1, n_estimators = 1000)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Gradient Boosting_0.01_1000'    : GradientBoostingClassifier(\n",
    "                                        random_state = random_no, learning_rate = 0.01, n_estimators = 1000)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-------------------------- APPLYING BASIC DATA MODELING --------------------------\\n')\n",
    "print('1. Applying stratified split b/w train and test. train/test split ratio is 0.8/0.2')\n",
    "\n",
    "splits = 5\n",
    "random_no = 0\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = (\n",
    "        splits - 1)/float(splits), random_state = random_no, stratify = y)\n",
    "\n",
    "models = {\n",
    "            'Gradient Boosting_0.001_1000'    : GradientBoostingClassifier(\n",
    "                                        random_state = random_no, learning_rate = 0.001, n_estimators = 1000)\n",
    "}\n",
    "\n",
    "print('2. Iterating through multiple classification models with random_state = 0')\n",
    "print('3. Applying cross validation with number of splits = 5 on train dataset')\n",
    "\n",
    "model_cs = defaultdict(float)\n",
    "\n",
    "for model_name, clf in models.items():\n",
    "    scores = cross_val_score(clf, train_X, train_y, cv = splits, scoring='accuracy')\n",
    "    model_cs[model_name] = scores.mean()\n",
    "\n",
    "print('4. Finding mean cross validation score for each model')\n",
    "\n",
    "for model_name, score in model_cs.items():\n",
    "    print(\"\\t{0:25} {1}\".format(model_name, str(score)))\n",
    "\n",
    "best_model = max(model_cs, key=model_cs.get)\n",
    "\n",
    "print('\\n5. Applying best model i.e. %s on the test dataset'%best_model)\n",
    "model = models[best_model]\n",
    "model.fit(train_X, train_y)\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "print('6. Finding accuracy using accuracy_score/clf.score')\n",
    "print('\\tTest accuracy score: %f\\n'%model.score(test_X, test_y))\n",
    "\n",
    "print('7. Populating the confusion matrix')\n",
    "print(confusion_matrix(test_y, pred_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
